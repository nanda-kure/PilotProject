# -*- coding: utf-8 -*-
"""Assesment_Neeraj.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Nu_vnYnhGTzyFLaR34B6QewwmqnaSWLC
"""

#Mount Google Drive
from google.colab import drive 
drive.mount('/content/drive')

#Create workspace folders
  root_dir='/content/drive/MyDrive'
  folder='/Assesment_Neeraj'
  gate1_dir='/Processing'
  gate2_dir='/Queue'
  gate3_dir='/Processed'
  folder_dir=root_dir+folder
  gate1_dir=folder_dir+gate1_dir 
  gate2_dir=folder_dir+gate2_dir 
  gate3_dir=folder_dir+gate3_dir
  os.mkdir(folder_dir)
  os.mkdir(gate1_dir)
  os.mkdir(gate2_dir)
  os.mkdir(gate3_dir)

# Commented out IPython magic to ensure Python compatibility.
#Uncomment Below line if commented 
# %cd '/content/drive/MyDrive/Assesment_Neeraj'

from random import randint 
from shutil import move
import sqlite3
from sqlite3 import Error
import time
import multiprocessing
import os

conn = sqlite3.connect("./files.db")
def create_table():
    query_create_files_table = """ CREATE TABLE IF NOT EXISTS files (
                                    fileid VARCHAR(10) PRIMARY KEY,
                                    processed INT NOT NULL
                                ); """
    if conn is not None:
        c=conn.cursor()
        c.execute(query_create_files_table)
    else:
        print("connection to DB is not available.")

    return

def create_file():
    while True:
        #creating an empty file in the processing folder:
        file_id=randint(0,1000);
        f= open(f"./Processing/{file_id}.txt","w+")
        f.close()
        # sleep for 1 s
        time.sleep(1)
    return;
    
def move_file(source:str,destination:int):
    move(source,destination)
    return;
    
def update_db(file_id:str,process_status:bool):
    # sql query to insert into the table:
    sql = ''' INSERT INTO files(fileid,processed)
            VALUES(?,?) '''
    # get the cursor object:
    c = conn.cursor()
    # execute the query:
    print(type(file_id),type(process_status))
    c.execute(sql, (str(file_id),int(process_status)))
    # commit to the database: 
    conn.commit()
    # return inserted row id
    print("inserted to the files table: ",c.lastrowid)
    return c.lastrowid

def processing():
    while True:
        time.sleep(5)
        # check if queue folder is empty:
        if len(os.listdir('./Queue/')) == 0:
            # list all the files in processing and move to queue:
            process_files=os.listdir("./Processing/")
            for file in process_files:
                move_file("./Processing/"+file,"./Queue/"+file)
                
            
            # list all the files in the queue and move to process:
            queue_files=os.listdir("./Queue/")
            for f in queue_files:
                fid=f.split("/")[-1]
                move_file("./Queue/"+f,"./Processed/"+f)
                update_db(f,1)
        
    return


if __name__=="__main__":
    create_table()

    p1 = multiprocessing.Process(target=create_file)
    p2 = multiprocessing.Process(target=processing)

    # starting process
    p1.start()
    p2.start()
  
    p1.join()
    p2.join()